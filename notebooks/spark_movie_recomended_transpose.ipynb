{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER = \"local\"\n",
    "NUM_PROCESSORS = \"4\"\n",
    "NUM_EXECUTORS = \"1\"\n",
    "NUM_PARTITIONS = 40\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import pyspark.sql.functions as psf\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f4aa8861a20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "\n",
    "conf.set(\"spark.app.name\", \"one_part_data\")\n",
    "conf.set(\"spark.master\", MASTER)\n",
    "conf.set(\"spark.executor.cores\", NUM_PROCESSORS)\n",
    "conf.set(\"spark.executor.instances\", NUM_EXECUTORS)\n",
    "conf.set(\"spark.executor.memory\", \"15g\")\n",
    "conf.set(\"spark.locality.wait\", \"0\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "conf.set(\"spark.kryoserializer.buffer.max\", \"2000\")\n",
    "conf.set(\"spark.executor.heartbeatInterval\", \"6000s\")\n",
    "conf.set(\"spark.network.timeout\", \"10000000s\")\n",
    "conf.set(\"spark.shuffle.spill\", \"true\")\n",
    "conf.set(\"spark.driver.memory\", \"15g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"15g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/14 11:25:24 WARN Utils: Your hostname, yagor-pc resolves to a loopback address: 127.0.1.1; using 192.168.0.107 instead (on interface enp7s0)\n",
      "22/12/14 11:25:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/14 11:25:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.107:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4a876d9ab0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .config(conf=conf) \\\n",
    "      .master(\"local[*]\") \\\n",
    "      .appName(\"SparkByExamples.com\") \\\n",
    "      .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "        StructField(\"user\", IntegerType()),\\\n",
    "        StructField(\"film\", IntegerType()), \\\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|user| film|\n",
      "+----+-----+\n",
      "|   0|16981|\n",
      "|   0|23846|\n",
      "|   0|27947|\n",
      "|   0|31189|\n",
      "|   0|31713|\n",
      "|   0|32947|\n",
      "|   0|33598|\n",
      "|   0|36763|\n",
      "|   0|38012|\n",
      "|   0|39632|\n",
      "|   0|39826|\n",
      "|   0|40069|\n",
      "|   0|40177|\n",
      "|   0|42118|\n",
      "|   0|43282|\n",
      "|   0|44186|\n",
      "|   0|44439|\n",
      "|   0|49093|\n",
      "|   0|49555|\n",
      "|   0|49739|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folderPath = \"/home/yagor/Рабочий стол/mipt/spark/train_0_part_data.csv\"\n",
    "df = spark.read.csv(folderPath, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('user', IntegerType(), True), StructField('film', IntegerType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116468778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  film|count|\n",
      "+------+-----+\n",
      "|373523|  776|\n",
      "|417183|  585|\n",
      "|108460| 2013|\n",
      "|197890| 4263|\n",
      "|203429|10146|\n",
      "|220674|11830|\n",
      "|200625|12263|\n",
      "|591532|13334|\n",
      "|628058| 1709|\n",
      "|259276| 6027|\n",
      "| 42468|  210|\n",
      "| 77422|   45|\n",
      "|180155| 7056|\n",
      "|188834|  838|\n",
      "|173914|13728|\n",
      "|225262| 2463|\n",
      "|396948|19929|\n",
      "|170862|12454|\n",
      "|193228| 2586|\n",
      "|716230| 1137|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values = df.groupBy('film').count()\n",
    "values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор 500 самых часто просматриваемых/популярных фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_sorted = values.sort('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  film|count|\n",
      "+------+-----+\n",
      "|691830|    1|\n",
      "|750322|    1|\n",
      "|214115|    1|\n",
      "|743340|    1|\n",
      "|164126|    1|\n",
      "|820116|    1|\n",
      "|704723|    1|\n",
      "|390441|    1|\n",
      "|209485|    1|\n",
      "| 90557|    1|\n",
      "|197651|    1|\n",
      "|417963|    1|\n",
      "|851631|    1|\n",
      "|314123|    1|\n",
      "| 40330|    1|\n",
      "|425197|    1|\n",
      "|815069|    1|\n",
      "|169572|    1|\n",
      "|540722|    1|\n",
      "|224450|    1|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values_sorted_part_list = values_sorted.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_sorted_part = spark.createDataFrame(data = values_sorted_part_list, schema = [\"film\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  film|count|\n",
      "+------+-----+\n",
      "|226442|16753|\n",
      "|321489|16760|\n",
      "|323232|16789|\n",
      "|395107|16795|\n",
      "|200249|16797|\n",
      "|332231|16833|\n",
      "|206272|16836|\n",
      "|376603|16837|\n",
      "|207079|16839|\n",
      "|218918|16857|\n",
      "|163617|16863|\n",
      "|228717|16878|\n",
      "|227173|16879|\n",
      "|264081|16880|\n",
      "|383534|16907|\n",
      "|205458|16919|\n",
      "|237383|16928|\n",
      "|204533|16933|\n",
      "|218533|16994|\n",
      "|193148|17003|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values_sorted_part.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_sorted_part.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df2 = df.groupBy(\"film\").agg(F.collect_list(\"user\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "547240"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|film|  collect_list(user)|\n",
      "+----+--------------------+\n",
      "|  28|[9151, 19312, 246...|\n",
      "|  31|             [80062]|\n",
      "|  34|            [105444]|\n",
      "|  53|             [11458]|\n",
      "|  65|[94699, 98105, 11...|\n",
      "|  85|             [75891]|\n",
      "| 101|[838, 10786, 1027...|\n",
      "| 108|[35222, 77924, 13...|\n",
      "| 115|      [30232, 38963]|\n",
      "| 137|      [81750, 95773]|\n",
      "| 183|[1495, 22656, 206...|\n",
      "| 193|[3924, 31201, 553...|\n",
      "| 210|[43302, 48541, 80...|\n",
      "| 251|            [125673]|\n",
      "| 255|[1813, 11939, 349...|\n",
      "| 296|[3031, 29807, 390...|\n",
      "| 321|[10018, 989, 1017...|\n",
      "| 322|[11077, 504, 1188...|\n",
      "| 362|             [38090]|\n",
      "| 368|[10318, 6706, 695...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(film=12, collect_list(user)=[81397])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(film=855760, collect_list(user)=[3096, 7591, 11382, 17435, 46587, 54408, 55663, 60672, 67620, 68567, 74894, 93917, 100526, 101049, 106280, 109668, 110864, 111457, 116906, 125847, 130535])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.join(values_sorted_part,'film','inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+\n",
      "|  film|  collect_list(user)|count|\n",
      "+------+--------------------+-----+\n",
      "|120663|[9962, 9, 9964, 1...|28747|\n",
      "|121002|[9962, 15, 9965, ...|17369|\n",
      "|121207|[9960, 4, 9961, 9...|30448|\n",
      "|125506|[7, 9961, 9, 9965...|20195|\n",
      "|192238|[9961, 5, 9962, 6...|24406|\n",
      "|198430|[9954, 16, 9962, ...|19761|\n",
      "|199203|[9964, 1, 9972, 5...|20265|\n",
      "|200249|[9963, 1, 9972, 3...|16797|\n",
      "|205458|[9962, 33, 9964, ...|16919|\n",
      "|214871|[9958, 6, 9963, 1...|23005|\n",
      "|216953|[9958, 18, 9963, ...|19618|\n",
      "|217062|[9958, 11, 9968, ...|18546|\n",
      "|220905|[9958, 17, 9963, ...|21910|\n",
      "|221341|[9958, 11, 9959, ...|25089|\n",
      "|221766|[9955, 6, 9958, 8...|24090|\n",
      "|223238|[9963, 1, 9970, 2...|23670|\n",
      "|224090|[9955, 6, 9958, 8...|40848|\n",
      "|224413|[9958, 1, 9959, 2...|33392|\n",
      "|224507|[9954, 12, 9958, ...|18295|\n",
      "|229578|[9958, 8, 9959, 1...|17245|\n",
      "+------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (сходство фильмов на основе просмотров пользователей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[film: int, collect_list(user): array<int>, count: bigint, rawFeatures: vector]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"collect_list(user)\", outputCol=\"rawFeatures\", numFeatures=10000, )\n",
    "featurizedData = hashingTF.transform(df3)\n",
    "featurizedData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm\")\n",
    "data = normalizer.transform(rescaledData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute matrix product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "res = data.alias(\"i\").join(data.alias(\"j\"), psf.col(\"i.film\") < psf.col(\"j.film\"))\\\n",
    "    .select(\n",
    "        psf.col(\"i.film\").alias(\"i\"), \n",
    "        psf.col(\"j.film\").alias(\"j\"), \n",
    "        dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\"))\\\n",
    "    .sort(\"i\", \"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:================================================>(39982 + 12) / 40000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|     i|     j|               dot|\n",
      "+------+------+------------------+\n",
      "|106985|107800|0.7056756236927901|\n",
      "|106985|108171|0.6663264787432368|\n",
      "|106985|108239|0.7047961684423472|\n",
      "|106985|108773|0.7101651181311384|\n",
      "|106985|110836|0.7134403697891201|\n",
      "|106985|111919|0.7219618446806243|\n",
      "|106985|112226|0.7034818715750314|\n",
      "|106985|112895|0.7247384373492936|\n",
      "|106985|113480|0.7052136145358082|\n",
      "|106985|114169|0.7430677575223128|\n",
      "|106985|114231|0.7058251544013512|\n",
      "|106985|114280|0.6651666663415046|\n",
      "|106985|115668|0.6823146499468209|\n",
      "|106985|116267|0.7313373313406346|\n",
      "|106985|118205|0.7000104308700368|\n",
      "|106985|119019|0.6982923189285579|\n",
      "|106985|120621|0.7024982289960983|\n",
      "|106985|120663|0.7404632371829023|\n",
      "|106985|120975|0.6775225513998767|\n",
      "|106985|121002|0.6783826197801929|\n",
      "+------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124750"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sort = res.sort(['i', 'dot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:===============================================>(39988 + 12) / 40000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|     i|     j|               dot|\n",
      "+------+------+------------------+\n",
      "|106985|218329|0.5824472100541838|\n",
      "|106985|228717|0.5840643942334456|\n",
      "|106985|217972|0.5846528703121342|\n",
      "|106985|218106|0.5892363744997995|\n",
      "|106985|218533|0.5897074470367715|\n",
      "|106985|237383|0.5899152191999293|\n",
      "|106985|229578|0.5917382949394276|\n",
      "|106985|214193|0.5919590249032748|\n",
      "|106985|224166|0.5922217811794538|\n",
      "|106985|231449|0.5926807081788006|\n",
      "|106985|235865|0.5956655980776531|\n",
      "|106985|225905|0.5974260528255337|\n",
      "|106985|239845| 0.598413683439196|\n",
      "|106985|227823|0.5995885435535463|\n",
      "|106985|224507|0.5999072907858585|\n",
      "|106985|227328|0.6001307660698709|\n",
      "|106985|240442|0.6021419575633536|\n",
      "|106985|233474|0.6027525033795953|\n",
      "|106985|218918|0.6029044480699042|\n",
      "|106985|235326|0.6040400690236306|\n",
      "+------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res_sort.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:==>     (11140 + 12) / 40000][Stage 121:>              (0 + 0) / 898]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:==>     (11200 + 13) / 40000][Stage 121:>              (0 + 0) / 898]\r"
     ]
    }
   ],
   "source": [
    "\n",
    "res_with_tresh = res.filter((res.dot <= 0.586))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:===================>                            (16185 + 12) / 40000]\r"
     ]
    }
   ],
   "source": [
    "res_with_tresh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res_with_tresh.write \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .csv(\"/home/yagor/Рабочий стол/mipt/spark/500res_new_tresh_58.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other (not uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res_with_tresh.repartition(1).write.format('com.databricks.spark.csv').save(\"/home/yagor/Рабочий стол/mipt/spark/500res.csv\", header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = res_with_tresh.groupBy(\"film\").agg(F.collect_list(\"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_tresh_ = res_with_tresh.groupBy(\"i\").agg(F.collect_list(\"j\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_tresh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_tresh.write.csv(f'res10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter('dot > 0').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  i|   j|dot|\n",
      "+---+----+---+\n",
      "|471| 833|0.0|\n",
      "|471|1088|0.0|\n",
      "|471|1238|0.0|\n",
      "|471|1342|0.0|\n",
      "|471|1580|0.0|\n",
      "|471|1591|0.0|\n",
      "|471|1829|0.0|\n",
      "|471|2122|0.0|\n",
      "|471|2866|0.0|\n",
      "|471|3749|0.0|\n",
      "|471|3794|0.0|\n",
      "|471|3918|0.0|\n",
      "|471|3997|0.0|\n",
      "|471|4818|0.0|\n",
      "|471|5156|0.0|\n",
      "|471|5518|0.0|\n",
      "|471|5803|0.0|\n",
      "|471|6466|0.0|\n",
      "|471|7253|0.0|\n",
      "|471|7754|0.0|\n",
      "+---+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "data.alias(\"i\").join(data.alias(\"j\"), psf.col(\"i.film\") < psf.col(\"j.film\"))\\\n",
    "    .select(\n",
    "        psf.col(\"i.film\").alias(\"i\"), \n",
    "        psf.col(\"j.film\").alias(\"j\"), \n",
    "        dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\"))\\\n",
    "    .sort(\"i\", \"j\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|film|  collect_list(user)|         rawFeatures|            features|                norm|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "| 471|            [137995]|(10000,[1759],[1.0])|(10000,[1759],[3....|(10000,[1759],[1.0])|\n",
      "| 833|[41326, 50660, 86...|(10000,[561,604,6...|(10000,[561,604,6...|(10000,[561,604,6...|\n",
      "|1088|[14709, 15331, 16...|(10000,[15,63,239...|(10000,[15,63,239...|(10000,[15,63,239...|\n",
      "|1238|[56843, 76606, 10...|(10000,[525,2412,...|(10000,[525,2412,...|(10000,[525,2412,...|\n",
      "|1342|[15751, 35509, 37...|(10000,[437,1768,...|(10000,[437,1768,...|(10000,[437,1768,...|\n",
      "|1580|[17427, 64685, 10...|(10000,[2502,6319...|(10000,[2502,6319...|(10000,[2502,6319...|\n",
      "|1591|        [6321, 8162]|(10000,[3555,4757...|(10000,[3555,4757...|(10000,[3555,4757...|\n",
      "|1829|[13375, 13780, 14...|(10000,[0,13,25,3...|(10000,[0,13,25,3...|(10000,[0,13,25,3...|\n",
      "|2122|             [40380]| (10000,[947],[1.0])|(10000,[947],[3.7...| (10000,[947],[1.0])|\n",
      "|2866|[29727, 94997, 96...|(10000,[3091,3254...|(10000,[3091,3254...|(10000,[3091,3254...|\n",
      "|3749|             [83332]|(10000,[8392],[1.0])|(10000,[8392],[3....|(10000,[8392],[1.0])|\n",
      "|3794|[54472, 109830, 1...|(10000,[1124,4715...|(10000,[1124,4715...|(10000,[1124,4715...|\n",
      "|3918|[13598, 13621, 13...|(10000,[0,14,23,2...|(10000,[0,14,23,2...|(10000,[0,14,23,2...|\n",
      "|3997|[40719, 44265, 53...|(10000,[253,732,1...|(10000,[253,732,1...|(10000,[253,732,1...|\n",
      "|4818|[15145, 15942, 26...|(10000,[227,239,2...|(10000,[227,239,2...|(10000,[227,239,2...|\n",
      "|5156|     [29524, 127051]|(10000,[1297,3881...|(10000,[1297,3881...|(10000,[1297,3881...|\n",
      "|5518|     [74646, 132503]|(10000,[4125,4674...|(10000,[4125,4674...|(10000,[4125,4674...|\n",
      "|5803|    [107697, 134693]|(10000,[5299,9318...|(10000,[5299,9318...|(10000,[5299,9318...|\n",
      "|6466|[15053, 22151, 23...|(10000,[134,413,1...|(10000,[134,413,1...|(10000,[134,413,1...|\n",
      "|7253|[43208, 59133, 78...|(10000,[681,2036,...|(10000,[681,2036,...|(10000,[681,2036,...|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered=data.filter('age > 0')\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[film: int, collect_list(user): array<int>, rawFeatures: vector]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"collect_list(user)\", outputCol=\"rawFeatures\", numFeatures=10000, )\n",
    "featurizedData = hashingTF.transform(df2)\n",
    "featurizedData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>  (190 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|film|            features|\n",
      "+----+--------------------+\n",
      "| 471|(10000,[1759],[3....|\n",
      "| 833|(10000,[561,604,6...|\n",
      "|1088|(10000,[15,63,239...|\n",
      "|1238|(10000,[525,2412,...|\n",
      "|1342|(10000,[437,1768,...|\n",
      "|1580|(10000,[2502,6319...|\n",
      "|1591|(10000,[3555,4757...|\n",
      "|1829|(10000,[0,13,25,3...|\n",
      "|2122|(10000,[947],[4.2...|\n",
      "|2866|(10000,[3091,3254...|\n",
      "|3749|(10000,[8392],[3....|\n",
      "|3794|(10000,[1124,4715...|\n",
      "|3918|(10000,[0,14,23,2...|\n",
      "|3997|(10000,[253,732,1...|\n",
      "|4818|(10000,[227,239,2...|\n",
      "|5156|(10000,[1297,3881...|\n",
      "|5518|(10000,[4125,4674...|\n",
      "|5803|(10000,[5299,9318...|\n",
      "|6466|(10000,[134,413,1...|\n",
      "|7253|(10000,[681,2036,...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=1) #IDF(inputCol=\"rawFeatures\", outputCol=\"features\") used\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"film\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm\")\n",
    "data = normalizer.transform(rescaledData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute matrix product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "mat = IndexedRowMatrix(\n",
    "    data.select(\"film\", \"norm\")\\\n",
    "        .rdd.map(lambda row: IndexedRow(row.film, row.norm.toArray()))).toBlockMatrix()\n",
    "dot = mat.multiply(mat.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|     i|     j|               dot|\n",
      "+------+------+------------------+\n",
      "|106985|217972|0.5846528703121342|\n",
      "|106985|218329|0.5824472100541838|\n",
      "|106985|228717|0.5840643942334456|\n",
      "|107800|237383| 0.579043681145354|\n",
      "|108171|190629|0.5855307770089813|\n",
      "|108171|193148|0.5743025408361803|\n",
      "|108171|197540|0.5848344617556166|\n",
      "|108171|200249|0.5855999706985752|\n",
      "|108171|200630|0.5750308535617188|\n",
      "|108171|204533|0.5834368737767368|\n",
      "|108171|205308|0.5787746446296952|\n",
      "|108171|205458|0.5758225088029106|\n",
      "|108171|206272|0.5821422772432235|\n",
      "|108171|214193|0.5562703952349195|\n",
      "|108171|215302|0.5813288020660338|\n",
      "|108171|216227|0.5855141405790075|\n",
      "|108171|216953|0.5768856233611499|\n",
      "|108171|217062|0.5770683441406884|\n",
      "|108171|217972|0.5534269082021103|\n",
      "|108171|218101|0.5805848728435947|\n",
      "+------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folderPath = \"/home/yagor/Рабочий стол/mipt/spark/500res_new_tresh_58.csv/part-00000-f6a9852e-a992-4232-a168-c14378ad4df5-c000.csv\"\n",
    "df = spark.read.option(\"header\", \"true\").csv(folderPath)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10210"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pair = df.filter((df.dot <= 0.57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_pair.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|     i|count|\n",
      "+------+-----+\n",
      "|234035|   29|\n",
      "|332231|   14|\n",
      "|227173|   87|\n",
      "|238664|    3|\n",
      "|207831|   12|\n",
      "|208479|   11|\n",
      "|221883|   33|\n",
      "|227823|   46|\n",
      "|234729|   25|\n",
      "|382841|    1|\n",
      "|220905|   35|\n",
      "|232437|   35|\n",
      "|110836|    1|\n",
      "|115668|    2|\n",
      "|233014|   22|\n",
      "|215340|    8|\n",
      "|125506|   17|\n",
      "|188668|   13|\n",
      "|235865|   70|\n",
      "|239845|   79|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values = df.groupBy('i').count()\n",
    "values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_norm_number = values.filter(('count >= 10'))\n",
    "rec_norm_number.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|     i|count|\n",
      "+------+-----+\n",
      "|234035|   29|\n",
      "|332231|   14|\n",
      "|227173|   87|\n",
      "|207831|   12|\n",
      "|208479|   11|\n",
      "|221883|   33|\n",
      "|227823|   46|\n",
      "|234729|   25|\n",
      "|220905|   35|\n",
      "|232437|   35|\n",
      "|233014|   22|\n",
      "|125506|   17|\n",
      "|188668|   13|\n",
      "|235865|   70|\n",
      "|239845|   79|\n",
      "|200249|  164|\n",
      "|218106|   92|\n",
      "|223625|   42|\n",
      "|240548|   38|\n",
      "|214193|  102|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_norm_number.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_sorted = rec_norm_number.sort('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|     i|count|\n",
      "+------+-----+\n",
      "|213654|   10|\n",
      "|238073|   10|\n",
      "|221404|   10|\n",
      "|206578|   11|\n",
      "|192238|   11|\n",
      "|208479|   11|\n",
      "|239621|   11|\n",
      "|207831|   12|\n",
      "|232522|   13|\n",
      "|188668|   13|\n",
      "|204093|   13|\n",
      "|197965|   13|\n",
      "|120975|   13|\n",
      "|120621|   14|\n",
      "|332231|   14|\n",
      "|187748|   14|\n",
      "|254046|   14|\n",
      "|212140|   15|\n",
      "|256526|   15|\n",
      "|210745|   15|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_sorted_part_list = values_sorted.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_sorted_part = spark.createDataFrame(data = values_sorted_part_list, schema = [\"i\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|     i|count|\n",
      "+------+-----+\n",
      "|108171|   42|\n",
      "|221918|   43|\n",
      "|215179|   45|\n",
      "|239341|   45|\n",
      "|227253|   45|\n",
      "|227823|   46|\n",
      "|231689|   46|\n",
      "|221825|   47|\n",
      "|239111|   47|\n",
      "|219998|   50|\n",
      "|233791|   50|\n",
      "|188313|   51|\n",
      "|228594|   51|\n",
      "|224131|   52|\n",
      "|199566|   52|\n",
      "|225066|   54|\n",
      "|221081|   54|\n",
      "|197479|   55|\n",
      "|215302|   55|\n",
      "|199598|   56|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values_sorted_part.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_sorted_part.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df2 = df.groupBy(\"i\").agg(F.collect_list(\"j\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|     i|     collect_list(j)|\n",
      "+------+--------------------+\n",
      "|106985|[217972, 218329, ...|\n",
      "|107800|            [237383]|\n",
      "|108171|[190629, 193148, ...|\n",
      "|108239|[217972, 218329, ...|\n",
      "|108773|[218329, 218533, ...|\n",
      "|110836|            [237383]|\n",
      "|112226|[217972, 218106, ...|\n",
      "|112895|[214193, 217972, ...|\n",
      "|113480|            [237383]|\n",
      "|114231|[217972, 218106, ...|\n",
      "|114280|[200249, 204533, ...|\n",
      "|115668|    [218533, 237383]|\n",
      "|118205|[217972, 218329, ...|\n",
      "|119019|[214193, 217972, ...|\n",
      "|120621|[214193, 217972, ...|\n",
      "|120975|[204533, 205308, ...|\n",
      "|121002|[163617, 190629, ...|\n",
      "|121351|[190629, 191918, ...|\n",
      "|123647|[200249, 202954, ...|\n",
      "|123920|[204533, 205308, ...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(i='106985', collect_list(j)=['217972', '218329', '228717'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(i='400784', collect_list(j)=['601086'])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.join(values_sorted_part,'i','inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+\n",
      "|     i|     collect_list(j)|count|\n",
      "+------+--------------------+-----+\n",
      "|108171|[190629, 193148, ...|   42|\n",
      "|221918|[242813, 244971, ...|   43|\n",
      "|215179|[254046, 256526, ...|   45|\n",
      "|239341|[242813, 244971, ...|   45|\n",
      "|227253|[228717, 230166, ...|   45|\n",
      "|227823|[252155, 254046, ...|   46|\n",
      "|231689|[238073, 250344, ...|   46|\n",
      "|221825|[224131, 225209, ...|   47|\n",
      "|239111|[242813, 252155, ...|   47|\n",
      "|219998|[221825, 222409, ...|   50|\n",
      "|233791|[238073, 242813, ...|   50|\n",
      "|188313|[214193, 215179, ...|   51|\n",
      "|228594|[232234, 234409, ...|   51|\n",
      "|224131|[224166, 224507, ...|   52|\n",
      "|199566|[214193, 215179, ...|   52|\n",
      "|225066|[242813, 244971, ...|   54|\n",
      "|221081|[224507, 227173, ...|   54|\n",
      "|197479|[214193, 215179, ...|   55|\n",
      "|215302|[242813, 244971, ...|   55|\n",
      "|199598|[214193, 215179, ...|   56|\n",
      "+------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df3.select(['i', 'collect_list(j)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|     i|     collect_list(j)|\n",
      "+------+--------------------+\n",
      "|108171|[190629, 193148, ...|\n",
      "|221918|[242813, 244971, ...|\n",
      "|215179|[254046, 256526, ...|\n",
      "|239341|[242813, 244971, ...|\n",
      "|227253|[228717, 230166, ...|\n",
      "|227823|[252155, 254046, ...|\n",
      "|231689|[238073, 250344, ...|\n",
      "|221825|[224131, 225209, ...|\n",
      "|239111|[242813, 252155, ...|\n",
      "|219998|[221825, 222409, ...|\n",
      "|233791|[238073, 242813, ...|\n",
      "|188313|[214193, 215179, ...|\n",
      "|228594|[232234, 234409, ...|\n",
      "|224131|[224166, 224507, ...|\n",
      "|199566|[214193, 215179, ...|\n",
      "|225066|[242813, 244971, ...|\n",
      "|221081|[224507, 227173, ...|\n",
      "|197479|[214193, 215179, ...|\n",
      "|215302|[242813, 244971, ...|\n",
      "|199598|[214193, 215179, ...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "R = Row('film', 'rec films')\n",
    "\n",
    "# use enumerate to add the ID column\n",
    "result_10 = spark.createDataFrame([R(i, x[:10]) for i, x in result.collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  film|           rec films|\n",
      "+------+--------------------+\n",
      "|108171|[190629, 193148, ...|\n",
      "|221918|[242813, 244971, ...|\n",
      "|215179|[254046, 256526, ...|\n",
      "|239341|[242813, 244971, ...|\n",
      "|227253|[228717, 230166, ...|\n",
      "|227823|[252155, 254046, ...|\n",
      "|231689|[238073, 250344, ...|\n",
      "|221825|[224131, 225209, ...|\n",
      "|239111|[242813, 252155, ...|\n",
      "|219998|[221825, 222409, ...|\n",
      "|233791|[238073, 242813, ...|\n",
      "|188313|[214193, 215179, ...|\n",
      "|228594|[232234, 234409, ...|\n",
      "|224131|[224166, 224507, ...|\n",
      "|199566|[214193, 215179, ...|\n",
      "|225066|[242813, 244971, ...|\n",
      "|221081|[224507, 227173, ...|\n",
      "|197479|[214193, 215179, ...|\n",
      "|215302|[242813, 244971, ...|\n",
      "|199598|[214193, 215179, ...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = result_10.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(film='108171', rec films=['190629', '193148', '197540', '200249', '200630', '204533', '205308', '205458', '206272', '214193']),\n",
       " Row(film='221918', rec films=['242813', '244971', '252155', '254046', '256526', '261023', '264081', '266755', '321489', '328238']),\n",
       " Row(film='215179', rec films=['254046', '256526', '257591', '260904', '261023', '321489', '323232', '328238', '332231', '335462']),\n",
       " Row(film='239341', rec films=['242813', '244971', '250344', '254046', '256526', '260904', '261023', '264081', '266755', '321489']),\n",
       " Row(film='227253', rec films=['228717', '230166', '231449', '250344', '252155', '254046', '256526', '257591', '260904', '261023']),\n",
       " Row(film='227823', rec films=['252155', '254046', '256040', '256526', '260904', '261023', '264081', '265875', '321489', '323232'])]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in result_10.collect():\n",
    "    key = i[0]\n",
    "    values =list(i[1])\n",
    "    res[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['190629',\n",
       " '193148',\n",
       " '197540',\n",
       " '200249',\n",
       " '200630',\n",
       " '204533',\n",
       " '205308',\n",
       " '205458',\n",
       " '206272',\n",
       " '214193']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['108171']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/home/yagor/Рабочий стол/mipt/spark/recomend_films.json\", \"w\") as fp:\n",
    "    json.dump(res , fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/yagor/Рабочий стол/mipt/spark/recomend_films.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['190629',\n",
       " '193148',\n",
       " '197540',\n",
       " '200249',\n",
       " '200630',\n",
       " '204533',\n",
       " '205308',\n",
       " '205458',\n",
       " '206272',\n",
       " '214193']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['108171']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fbacc38e156424bc4feb2fa78cad4dfa544bcce4e4fb367bb488859be726019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
